---
phase: 02-core-recording-transcription
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - OptionC/Clipboard/ClipboardManager.swift
  - OptionC/Recording/RecordingController.swift
  - OptionC/State/AppState.swift
autonomous: true

must_haves:
  truths:
    - "User can start recording by pressing Option-C"
    - "User can stop recording by pressing Option-C again (toggle mode)"
    - "User can hold Option-C to record and release to stop (push-to-talk mode)"
    - "Transcribed text is copied to clipboard when recording stops"
    - "Clipboard contains transcription result after successful recording"
  artifacts:
    - path: "OptionC/Clipboard/ClipboardManager.swift"
      provides: "NSPasteboard atomic writes with verification"
      exports: ["ClipboardManager", "copy"]
    - path: "OptionC/Recording/RecordingController.swift"
      provides: "Coordinates audio capture and transcription"
      exports: ["RecordingController", "startRecording", "stopRecording", "requestPermissions"]
    - path: "OptionC/State/AppState.swift"
      provides: "State coordinator with hotkey integration"
      exports: ["AppState", "handleKeyDown", "handleKeyUp"]
  key_links:
    - from: "AppState"
      to: "RecordingController"
      via: "handleKeyDown/handleKeyUp calls startRecording/stopRecording"
      pattern: "recordingController\\.(start|stop)Recording"
    - from: "RecordingController"
      to: "AudioCaptureManager"
      via: "startRecording creates request and starts capture"
      pattern: "audioCaptureManager\\.startCapture"
    - from: "RecordingController"
      to: "TranscriptionEngine"
      via: "startRecording calls transcribe with request"
      pattern: "transcriptionEngine\\.transcribe"
    - from: "RecordingController"
      to: "ClipboardManager"
      via: "transcription completion calls copy"
      pattern: "ClipboardManager\\.copy"
---

<objective>
Wire up the complete voice-to-clipboard flow with hotkey integration.

Purpose: Connect audio capture and transcription (from Plan 01) to the user interface, enabling the full Option-C workflow: press hotkey → record → transcribe → clipboard.

Output: ClipboardManager for atomic clipboard writes, RecordingController that orchestrates the pipeline, and updated AppState with dual-mode hotkey handling (toggle and push-to-talk).
</objective>

<execution_context>
@/Users/connecteddale/.claude/get-shit-done/workflows/execute-plan.md
@/Users/connecteddale/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-recording-transcription/02-RESEARCH.md
@.planning/phases/02-core-recording-transcription/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ClipboardManager</name>
  <files>OptionC/Clipboard/ClipboardManager.swift</files>
  <action>
Create ClipboardManager struct with atomic clipboard operations.

Implementation requirements:
1. Mark as @MainActor (NSPasteboard must be accessed on main thread)
2. Define ClipboardError enum: writeFailed, verificationFailed
3. Implement static copy(_ text: String) throws method:
   - Get NSPasteboard.general
   - Call pasteboard.clearContents()
   - Call pasteboard.setString(text, forType: .string)
   - Guard success else throw ClipboardError.writeFailed
   - Verify: read back with pasteboard.string(forType: .string)
   - Guard readBack == text else throw ClipboardError.verificationFailed

Pattern from research: Clear before write, verify after write. This ensures atomic operation and catches race conditions with clipboard managers.

Keep it simple - no retry logic for MVP. Error handling will be added in Phase 3.
  </action>
  <verify>
File exists at OptionC/Clipboard/ClipboardManager.swift with:
- @MainActor annotation
- ClipboardError enum with writeFailed and verificationFailed
- Static copy method that clears, writes, and verifies
- Uses NSPasteboard.general
  </verify>
  <done>
ClipboardManager compiles and provides atomic clipboard writes with verification for transcription results.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create RecordingController</name>
  <files>OptionC/Recording/RecordingController.swift</files>
  <action>
Create RecordingController class that orchestrates the audio-to-clipboard pipeline.

Implementation requirements:
1. Class annotated with @MainActor, conforms to ObservableObject
2. Private instances of AudioCaptureManager and TranscriptionEngine
3. Private recognitionRequest: SFSpeechAudioBufferRecognitionRequest? for current session
4. @Published var transcribedText: String = "" for partial results
5. @Published var isRecording: Bool = false

Implement requestPermissions() async -> Bool:
- Request microphone: await AVCaptureDevice.requestAccess(for: .audio)
- Request speech recognition using SFSpeechRecognizer.requestAuthorization with continuation
- Return true only if both granted

Implement startRecording() throws:
- Guard not already recording
- Create fresh SFSpeechAudioBufferRecognitionRequest()
- Start transcription engine with request (async, fires completion later)
- Start audio capture with same request
- Set isRecording = true

Implement stopRecording() async -> String?:
- Guard currently recording
- Call recognitionRequest?.endAudio() - CRITICAL: must call before stopping capture
- Stop audio capture
- Set isRecording = false
- Wait for transcription completion (or use existing partial result if final already received)
- Copy result to clipboard via ClipboardManager.copy()
- Return transcribed text

Critical ordering from research:
1. endAudio() on request FIRST
2. Then stop audio capture
3. This signals recognizer to finalize transcription

Use onPartialResult callback to update transcribedText for live preview (optional, can show in menu).
  </action>
  <verify>
File exists at OptionC/Recording/RecordingController.swift with:
- @MainActor + ObservableObject
- AudioCaptureManager and TranscriptionEngine instances
- requestPermissions method checking both mic and speech
- startRecording that creates request and starts both capture and transcription
- stopRecording that calls endAudio() BEFORE stopping capture
- ClipboardManager.copy called with result
  </verify>
  <done>
RecordingController compiles and orchestrates the complete pipeline from hotkey trigger to clipboard result.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update AppState with Hotkey Handling</name>
  <files>OptionC/State/AppState.swift</files>
  <action>
Update AppState (created in Phase 1) to integrate RecordingController and support both recording modes.

Add to existing AppState class:
1. Private let recordingController = RecordingController()
2. Ensure RecordingMode enum exists: toggle, pushToTalk
3. @AppStorage("recordingMode") var recordingMode: RecordingMode = .toggle

Update KeyboardShortcuts registration in init():
- Use onKeyDown for starting push-to-talk mode
- Use onKeyUp for toggle mode and ending push-to-talk

Implement handleKeyDown():
```swift
func handleKeyDown() {
    guard currentState == .idle else { return }

    if recordingMode == .pushToTalk {
        // Push-to-talk: start on key down
        Task { await startRecording() }
    }
    // Toggle mode: do nothing on key down
}
```

Implement handleKeyUp():
```swift
func handleKeyUp() {
    switch recordingMode {
    case .toggle:
        // Toggle: flip state on key up
        switch currentState {
        case .idle:
            Task { await startRecording() }
        case .recording:
            Task { await stopRecording() }
        case .processing:
            break // Ignore while processing
        }
    case .pushToTalk:
        // Push-to-talk: stop on key up
        if currentState == .recording {
            Task { await stopRecording() }
        }
    }
}
```

Implement private startRecording() async:
- Check permissions first: await recordingController.requestPermissions()
- If denied, stay idle (error handling in Phase 3)
- try recordingController.startRecording()
- Set currentState = .recording

Implement private stopRecording() async:
- Set currentState = .processing
- let text = await recordingController.stopRecording()
- Set currentState = .idle
- (Notification of success/failure is Phase 3)

Wire up KeyboardShortcuts in init:
```swift
KeyboardShortcuts.onKeyDown(for: .toggleRecording) { [weak self] in
    self?.handleKeyDown()
}
KeyboardShortcuts.onKeyUp(for: .toggleRecording) { [weak self] in
    self?.handleKeyUp()
}
```
  </action>
  <verify>
File at OptionC/State/AppState.swift updated with:
- RecordingController instance
- handleKeyDown and handleKeyUp methods
- Both onKeyDown and onKeyUp registered for .toggleRecording
- Toggle mode uses keyUp only
- Push-to-talk uses keyDown to start, keyUp to stop
- State transitions: idle → recording → processing → idle
  </verify>
  <done>
AppState integrates recording controller with dual-mode hotkey handling. User can record via toggle (press twice) or push-to-talk (hold and release).
  </done>
</task>

</tasks>

<verification>
1. All three files compile without errors
2. ClipboardManager.copy writes to system clipboard and can be verified with Cmd+V
3. RecordingController.stopRecording calls endAudio() before stopping capture
4. AppState.handleKeyDown starts recording in push-to-talk mode only
5. AppState.handleKeyUp handles both toggle and push-to-talk mode correctly
6. Full flow: Option-C → record → transcribe → clipboard works end-to-end
</verification>

<success_criteria>
- User can press Option-C to start recording, press again to stop (toggle mode)
- User can hold Option-C to record, release to stop (push-to-talk mode)
- Transcription result appears on clipboard after recording stops
- State transitions correctly: idle → recording → processing → idle
- Clipboard contains accurate transcription of spoken audio
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-recording-transcription/02-02-SUMMARY.md`
</output>
